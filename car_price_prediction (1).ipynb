{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual/Team\n",
        "##### **Team Member 1 - Raj vardhan - 2210990710**\n",
        "##### **Team Member 2 - Rohan - 2210990737**\n",
        "##### **Team Member 3 - Vanshul Rana - 2210992511**\n",
        "##### **Team Member 4 -Krishna - 2210931008**"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The car price prediction project utilizes machine learning techniques to estimate the prices of cars based on various features. The dataset comprises information about different car models, including their make, model, year of manufacture, mileage, engine size, fuel type, and other relevant attributes. The goal of the project is to develop a predictive model that accurately estimates the prices of cars, helping buyers, sellers, and manufacturers make informed decisions.\n",
        "\n",
        "The project begins with data preprocessing steps, including handling missing values, encoding categorical variables, and scaling numerical features to ensure the quality and consistency of the dataset. Various machine learning algorithms are explored, including linear regression, decision trees, random forests, and gradient boosting, to determine the most suitable model for the task.\n",
        "\n",
        "After training and evaluating several models using techniques such as cross-validation, the performance of each model is assessed using metrics such as mean absolute error (MAE), mean squared error (MSE), and R-squared (R2) score. The model with the lowest error metrics and the highest R-squared score is selected as the final predictive model.\n",
        "\n",
        "Insights gained from the analysis reveal the key features that significantly influence car prices, such as the car's make, model, year of manufacture, and mileage. The model's predictions provide valuable insights into the factors driving car prices, enabling stakeholders to make informed decisions about buying, selling, or pricing cars in the market."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In today's automotive market, the pricing of cars is a complex and multifaceted task influenced by numerous factors such as brand reputation, vehicle specifications, market demand, economic conditions, and consumer preferences. Car manufacturers and dealerships face the challenge of accurately pricing their vehicles to remain competitive, maximize profits, and meet customer expectations. To address this challenge, the development of predictive models using Artificial Intelligence (AI) and Machine Learning (ML) techniques presents a promising solution."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df=pd.read_csv(\"/content/CarPrice_project.csv\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for column in df.columns:\n",
        "    unique_values = df[column].unique()\n",
        "    print(f\"Unique values for {column}:\")\n",
        "    print(unique_values)\n",
        "    print()\n",
        "\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "#price of car\n",
        "Price=pd.DataFrame({\n",
        "    'car_Id':[1,2,3,4,5,6,7,8,9,10],\n",
        "    'price':['13495','16500','16500','13950','17450','15250','17710','18920','23875','17859.17']})\n",
        "print(Price)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.grouping data\n",
        "\n",
        "CarName={'carName':[\"alfa-romero giulia\",\" alfa-romero stelvio\",\"alfa-romero Quadrifoglio \",\"audi 100 ls\",\"audi 100ls\",\"audi fox\",\"audi 100ls\",\"audi 5000\",\"audi 4000\",\"audi 5000s (diesel)\"],\n",
        "         'fueltype':['gas','gas','gas','gas','gas','gas','gas','gas','gas','gas'],\n",
        "         'carbody':[\"convertible\",\"convertible\",\"hatchback\",\"sedan\",\"sedan\",\"sedan\",\"sedan\",\"wagon\",\"sedan\",\"hatchback\"],\n",
        "         'enginesize':[130,130,152,109,136,136,136,136,131,131]\n",
        "}\n",
        "\n",
        "df=pd.DataFrame(CarName)\n",
        "grouped=df.groupby('enginesize')\n",
        "print(grouped.get_group(136))"
      ],
      "metadata": {
        "id": "UIJ-f-vmRcFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.concatenating the dataframes\n",
        "df=pd.DataFrame({\n",
        "    'enginetype':['dohc','dohc','ohcv','ohc','ohc','ohc','ohc','ohc','ohc','ohc'],\n",
        "    'cylindernumber':['four','four','six','four','five','five','five','five','five','five']\n",
        "})\n",
        "df"
      ],
      "metadata": {
        "id": "aJr8UEfeTL_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have done the following manipulations:-\n",
        "1.data exploration\n",
        "2.merge two data frame\n",
        "3.grouping data\n",
        "4.visualizing the data\n",
        "5.filtering the data\n",
        "6.concatenating the data."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "# Selecting the bottom 20 rows of data\n",
        "df_subset = df.tail(20)\n",
        "\n",
        "# Plotting pie chart for 'wheelbase'\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(df_subset['wheelbase'], labels=df_subset['wheelbase'], autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Distribution of Wheelbase')\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proportion Visualization: Pie charts are ideal for visualizing proportions of a whole. In this case, the pie chart shows the distribution of different wheelbase lengths within the bottom 40 rows of the dataset.\n",
        "\n",
        "Limited Number of Categories: Pie charts work well when there are a limited number of categories to represent. Since we are visualizing the wheelbase lengths, which are continuous variables, but are effectively categorized within the dataset, a pie chart can effectively show the relative frequencies of these categories"
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dominant Wheelbase Lengths: Observing the size of each slice in the pie chart can provide insights into which wheelbase lengths are most prevalent within the bottom 40 rows of the dataset. Larger slices indicate more common wheelbase lengths, while smaller slices represent less common lengths.\n",
        "\n",
        "Variety of Wheelbase Lengths: Examining the number of distinct wheelbase lengths represented in the pie chart can reveal insights into the diversity of wheelbase options within the dataset. A larger number of distinct slices suggests a wider range of wheelbase lengths available in the dataset.\n",
        "\n",
        "Concentration of Wheelbase Lengths: Analyzing whether certain wheelbase lengths dominate the distribution or if the distribution is relatively evenly spread across different lengths can provide insights into market preferences or manufacturing trends. Concentrated distributions may indicate that specific wheelbase lengths are more popular among consumers or more commonly produced by manufacturers"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Market Segmentation: Understanding the distribution of wheelbase lengths can help businesses tailor their product offerings to better meet the needs and preferences of different customer segments. By offering a diverse range of wheelbase options, businesses can attract a wider customer base and increase sales.\n",
        "\n",
        "Product Development: Insights from the distribution of wheelbase lengths can inform product development strategies, allowing businesses to design vehicles that cater to specific market niches or emerging trends. Developing vehicles with popular wheelbase lengths can enhance competitiveness and drive revenue growth.\n",
        "\n",
        "Negative Business Impact:\n",
        "\n",
        "Misalignment with Market Demand: Misinterpreting the distribution of wheelbase lengths or failing to accurately assess market demand can lead to negative growth. For example, if a business produces vehicles with wheelbase lengths that are not aligned with customer preferences or market trends, it may struggle to attract buyers and experience declining sales.\n",
        "\n",
        "Excess Inventory: Overestimating demand for certain wheelbase lengths and producing vehicles in excess can result in excess inventory, leading to storage costs, markdowns, and reduced profit margins. Businesses may need to implement discounting strategies or liquidate inventory to clear excess stock, resulting in financial losses"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "\n",
        "# Extracting the first 20 data points\n",
        "data_subset = df.head(20)\n",
        "\n",
        "# Plotting the bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(data_subset['CarName'], data_subset['price'], color='skyblue')\n",
        "plt.xlabel('Car Name')\n",
        "plt.ylabel('Price')\n",
        "plt.title('Car Price for First 20 Data Points')\n",
        "plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clear Representation: Bar charts provide a clear visual representation of the data. The length of each bar corresponds directly to the value being represented (average price), making it intuitive for viewers to interpret the data.\n",
        "\n",
        "Categorical Data: Since car makes are categorical data (e.g., Toyota, Honda, Ford), a bar chart is appropriate for displaying this type of information. Each bar represents a distinct category, making it easy to understand the distribution of average prices across different makes."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here Price Comparison: The chart facilitates a direct comparison of average prices between car makes. Viewers can easily identify which makes are generally more expensive or more affordable relative to others. This comparison can inform purchasing decisions and provide insights into the perceived value of different car brands.\n",
        "\n"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Optimized Pricing Strategies: Identifying pricing patterns and trends between the two datasets can help businesses refine their pricing strategies. They can adjust prices for specific models to remain competitive in the market while maximizing profitability.\n",
        "\n",
        "Market Positioning: Understanding price differences can provide insights into how the business is positioned relative to competitors. This information can guide decisions on whether to target premium or budget segments of the market and tailor marketing strategies accordingly.\n",
        "\n",
        "Negative Business Impact:\n",
        "\n",
        "Loss of Market Share: If the analysis reveals that prices in one dataset are consistently lower than those in the other dataset for comparable models, it could indicate that the business is overpricing its products. This may lead to a loss of market share as customers opt for more competitively priced alternatives.\n",
        "\n",
        "Perceived Value: Large discrepancies in prices between the two datasets for the same models may raise questions about the perceived value of the products. Customers may become skeptical about the pricing integrity of the business, leading to a negative impact on brand reputation and customer loyalty."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "data_subset = df.head(20)\n",
        "\n",
        "# Plotting the line chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(data_subset.index, data_subset['price'], marker='*', color='skyblue', linestyle='-')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Price')\n",
        "plt.title('Car Prices for First 20 Data Points')\n",
        "plt.xticks(data_subset.index)  # Use data indices as x-axis ticks\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trend Analysis: A line chart is effective for visualizing trends over time. In this case, plotting car prices against years allows us to observe how prices have changed over different time periods. This is valuable for identifying long-term trends, seasonal patterns, or any other temporal variations in car prices.\n",
        "\n",
        "Comparison: Line charts allow for easy comparison between different categories or series. If there are multiple car makes or models in the dataset, each can be represented by a separate line on the chart, enabling viewers to compare the price trends of different cars over time."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Identifying Growth Opportunities: By analyzing the trends in car prices over time, businesses can identify periods of increasing demand or rising prices. This insight can help businesses capitalize on growth opportunities by adjusting their inventory, pricing strategies, and marketing efforts accordingly.\n",
        "\n",
        "Optimizing Inventory Management: Understanding how car prices fluctuate over time allows businesses to better manage their inventory. They can anticipate changes in demand and adjust their inventory levels to meet customer needs effectively, minimizing the risk of overstocking or stockouts.\n",
        "\n",
        "Negative Growth Potential:\n",
        "\n",
        "Identifying Declining Trends: While positive growth opportunities can be identified through upward trends in car prices, businesses must also be vigilant for declining trends. If the line chart reveals a consistent downward trend in car prices over time, it may indicate a shrinking market or declining consumer interest. Failing to recognize and address such trends promptly could lead to negative growth for the business.\n",
        "\n",
        "Market Saturation: A flat or stagnant trend in car prices over time may suggest market saturation, where demand for new cars is reaching a plateau. Businesses operating in saturated markets may face increased competition and pricing pressures, making it challenging to achieve growth without innovative strategies to differentiate their offerings."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "\n",
        "# scatter plot\n",
        "\n",
        "plt.scatter(df['horsepower'],df['citympg'],color='red',marker='+')\n",
        "plt.title('scatter plot btw horsepower and citympg')\n",
        "plt.xlabel('horsepower')\n",
        "plt.ylabel('citympg')\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a scatter plot because it's a commonly used chart type for visualizing the relationship between two continuous variables, such as horsepower and price in this case. Scatter plots are effective for identifying patterns, trends, and correlations in the data. By plotting price against horsepower, we can visually inspect if there's any discernible relationship between these two variables, such as whether cars with higher horsepower tend to have higher prices. If there's a relationship, it might be useful for understanding the pricing dynamics in the automotive market. Additionally, scatter plots are straightforward to interpret and communicate the data effectively to others."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpreting insights from a scatter plot involves examining the pattern or trend between the two variables plotted. Here are some potential insights that could be derived from the scatter plot of price against horsepower:\n",
        "\n",
        "Positive correlation: If the points on the scatter plot generally slope upwards from left to right, it suggests a positive correlation between horsepower and price. In other words, cars with higher horsepower tend to have higher prices.\n",
        "\n",
        "No correlation: If the points on the scatter plot appear scattered randomly without any clear pattern, it suggests that there is no significant relationship between horsepower and price.\n",
        "\n",
        "Outliers: Identification of outliers can provide insights into exceptional cases where cars may have unusually high or low prices given their horsepower. These outliers might represent unique models, luxury vehicles, or instances of pricing anomalies.\n",
        "\n",
        "Clusters or patterns: Clusters or patterns in the scatter plot may indicate specific segments of the market where certain types of cars (e.g., high-performance sports cars, economy cars) are priced differently relative to their horsepower.\n",
        "\n",
        "Potential for non-linear relationships: While a linear trend is commonly assumed, the scatter plot might reveal that the relationship between price and horsepower is non-linear. This could indicate that factors other than horsepower also influence the pricing of cars."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights gained from analyzing the relationship between price and horsepower in the automotive market can indeed have a positive business impact if leveraged effectively. Here's how:\n",
        "\n",
        "Optimized Pricing Strategies: Understanding the positive correlation between price and horsepower can help automotive companies and dealerships optimize their pricing strategies. They can price high-horsepower vehicles accordingly, maximizing profits without deterring potential buyers.\n",
        "\n",
        "Product Development: Insight into the preferences of consumers regarding horsepower and price can guide product development efforts. Manufacturers can adjust their product offerings to cater to market demand, potentially developing new models or enhancing existing ones to align with consumer expectations.\n",
        "\n",
        "However, there are potential negative impacts if the insights are not properly interpreted or addressed:\n",
        "\n",
        "Overpricing or Underpricing: Relying solely on the positive correlation between price and horsepower without considering other factors may lead to overpricing or underpricing of vehicles. Overpricing can deter potential buyers, while underpricing may result in missed revenue opportunities or reduced profit margins.\n",
        "\n",
        "Market Segmentation Issues: Focusing too narrowly on high-horsepower vehicles may neglect other segments of the market with different preferences or budget constraints. This could result in missed opportunities to capture market share from competitors or meet the needs of diverse customer segments."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "# Selecting only the first 30 rows of data\n",
        "df_subset = df.head(30)\n",
        "\n",
        "# Plotting histogram for 'CarName'\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(df_subset['CarName'], bins=15, color='orange', edgecolor='black')\n",
        "plt.title('Histogram of Car Names')\n",
        "plt.xlabel('Car Name')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=90)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparative Analysis: By plotting histograms for multiple categorical variables, we can compare the frequency distributions of different categories within each variable. This allows for easy identification of patterns or differences in the data.\n",
        "\n",
        "Readability: Histograms are easy to interpret and understand, making them suitable for communicating insights to others. They present the data in a clear and concise manner, facilitating quick comprehension of the frequency distribution."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variety of Car Models: Analyzing the spread of frequencies across different car names can highlight the diversity of car models available in the dataset. A wide range of car models with varying frequencies suggests a diverse product portfolio.\n",
        "\n",
        "Preference for Car Body Types: Understanding the distribution of car body types can indicate consumer preferences or trends in the market. For instance, if hatchbacks have a higher frequency compared to other body types, it suggests a preference for compact and versatile vehicles.\n",
        "\n",
        "Identification of Outliers: Unusually tall bars or unexpected patterns in the histograms may indicate outliers or anomalies in the data. These outliers could represent rare or niche car models that require further investigation"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "positive impact Product Development: Insights into consumer preferences for certain car models or body types can guide product development efforts. Businesses can prioritize the development of new models or variants that are in high demand, enhancing their competitiveness in the market.\n",
        "\n",
        "Inventory Management: Knowledge of popular car models and body types can inform inventory management decisions, allowing businesses to optimize their stock levels to meet customer demand more effectively. This can lead to improved efficiency and reduced inventory costs\n",
        "\n",
        "Negative Business Impact:\n",
        "\n",
        "Overlooked Market Segments: Focusing exclusively on the most popular car models or body types identified in the histograms may lead to overlooking niche or emerging market segments. Neglecting these segments could result in missed opportunities for growth and potential loss of market share to competitors who cater to these segments.\n",
        "\n",
        "Limited Product Differentiation: Relying solely on insights from histograms may result in limited product differentiation strategies. Businesses may fail to differentiate their offerings sufficiently from competitors, leading to commoditization and price-based competition that can erode profit margins"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "\n",
        "# Extracting the first 20 data points\n",
        "data_subset = df.head(20)\n",
        "\n",
        "# Define attributes to compare (assuming 'CarName', 'horsepower', and 'Price' here)\n",
        "attributes = ['CarName', 'horsepower', 'price']\n",
        "\n",
        "# Plotting the multiple bar chart without a loop\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plotting the first attribute ('CarName')\n",
        "plt.subplot(1, len(attributes), 1)\n",
        "plt.bar(data_subset.index, data_subset[attributes[0]], label=attributes[0], color='skyblue')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel(attributes[0])\n",
        "plt.title(attributes[0] + ' for First 20 Data Points')\n",
        "plt.xticks(data_subset.index)\n",
        "plt.legend()\n",
        "\n",
        "# Plotting the second attribute ('horsepower')\n",
        "plt.subplot(1, len(attributes), 2)\n",
        "plt.bar(data_subset.index, data_subset[attributes[1]], label=attributes[1], color='lightgreen')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel(attributes[1])\n",
        "plt.title(attributes[1] + ' for First 20 Data Points')\n",
        "plt.xticks(data_subset.index)\n",
        "plt.legend()\n",
        "\n",
        "# Plotting the third attribute ('Price')\n",
        "plt.subplot(1, len(attributes), 3)\n",
        "plt.bar(data_subset.index, data_subset[attributes[2]], label=attributes[2], color='salmon')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel(attributes[2])\n",
        "plt.title(attributes[2] + ' for First 20 Data Points')\n",
        "plt.xticks(data_subset.index)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical and Numerical Data: The chart effectively combines categorical data (car names) with numerical data (car lengths). This makes it suitable for visualizing the relationship between car names and their corresponding lengths.\n",
        "\n",
        "Readability: Multiple bar charts are easy to interpret, making them suitable for communicating insights to a broad audience. The clear labeling of car names on the x-axis and the corresponding lengths on the y-axis facilitates easy understanding of the data.\n",
        "\n",
        "Flexibility: This chart type provides flexibility in terms of customization. You can adjust parameters such as figure size, colors, and orientation of labels to enhance readability and aesthetics."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identification of Longest and Shortest Cars: The bar chart allows for easy identification of the longest and shortest cars among the models included in the dataset. The tallest bar represents the longest car, while the shortest bar represents the shortest car.\n",
        "\n",
        "Comparison of Car Lengths: Comparing the lengths of different car models can reveal patterns or trends in car design or market segmentation. For example, certain car manufacturers may produce longer vehicles on average, while others may focus on compact models."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Product Development: Insights into car lengths can inform product development strategies, allowing businesses to design vehicles that align with consumer preferences. By understanding which car lengths are popular or desirable, businesses can develop new models that cater to specific market segments, potentially leading to increased sales and market share.\n",
        "\n",
        "Market Positioning: Knowledge of car lengths across different models can help businesses strategically position their products in the market. For example, if there's a demand for longer luxury vehicles, businesses can focus on marketing their high-end models with spacious interiors and advanced features to target affluent consumers.\n",
        "\n",
        "Negative Business Impact:\n",
        "\n",
        "Misalignment with Consumer Preferences: If businesses misinterpret or overlook insights from the chart, they may develop products that do not align with consumer preferences. For example, investing in the production of longer vehicles when there's actually a growing demand for compact cars could result in excess inventory and decreased profitability.\n",
        "\n",
        "Market Saturation: Overemphasis on certain car lengths based on insights from the chart without considering broader market trends could lead to market saturation. If businesses flood the market with similar products, it may dilute brand value and erode pricing power, ultimately resulting in negative growth."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "\n",
        "# Selecting the first 20 rows of data\n",
        "df_subset = df.head(20)\n",
        "\n",
        "# Create violin plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.violinplot(x='citympg', y='highwaympg', data=df_subset)\n",
        "plt.title('Violin Plot of Car Price by Car Name')\n",
        "plt.xlabel('Citympg')\n",
        "plt.ylabel('highwaympg')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution Comparison: Violin plots provide a clear visual representation of the distribution of data within each category. The width of the violin corresponds to the frequency or density of data points at different values of the numerical variable.\n",
        "\n",
        "Summary Statistics: Violin plots often include summary statistics such as median, quartiles, and outliers, providing additional insights into the distribution of the data within each category."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variability in Car Prices: The width and shape of each violin indicate the variability in car prices for each car name. A wider section of the violin suggests greater variability in prices within that category, while a narrower section indicates more uniform pricing.\n",
        "\n",
        "Central Tendency: The central point or the thickest part of each violin represents the median car price for the corresponding car name. Comparing these central tendencies across different car names can provide insights into the typical pricing range for each model"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Informed Pricing Strategies: Understanding the variability in car prices and identifying popular price segments can help businesses develop more informed pricing strategies. By aligning pricing with customer preferences and market demand, businesses can attract more customers and increase sales, leading to positive growth.\n",
        "\n",
        "Market Segmentation Opportunities: Insights into the distribution of car prices across different car names can help identify opportunities for market segmentation. Businesses can tailor their marketing and product offerings to target specific customer segments based on their preferences for price ranges and car models, leading to increased customer satisfaction and loyalty\n",
        "\n",
        "Negative Business Impact:\n",
        "\n",
        "Lost Sales Opportunities: Misinterpreting pricing insights or failing to adjust pricing strategies in response to market dynamics can lead to lost sales opportunities. For example, pricing cars above the preferred price segments of target customers may result in decreased demand and negative growth.\n",
        "\n",
        "Brand Perception Damage: Inconsistent pricing or pricing outliers compared to competitors within the same car segment can damage brand perception and erode customer trust. Customers may perceive such pricing strategies as unfair or unjustified, leading to negative word-of-mouth and reputational damage."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "\n",
        "# Extracting the first 60 data points\n",
        "data_subset = df.head(60)\n",
        "\n",
        "# Creating the strip plot\n",
        "plt.figure(figsize=(15, 10))\n",
        "sns.stripplot(x='carheight', y='carwidth', data=data_subset, jitter=True)\n",
        "plt.xlabel('Car Height')\n",
        "plt.ylabel('Car Width')\n",
        "plt.title('Strip Plot between Car Height and Car Width (First 40 Data Points)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Individual Data Points: A strip plot displays individual data points, providing a detailed view of the distribution of the numerical variable within each category. This allows for precise interpretation of the data and identification of outliers or patterns.\n",
        "\n",
        "Categorical Comparison: Strip plots allow for easy comparison of the distribution of the numerical variable across different categories. By plotting all data points for each category along the same axis, viewers can quickly assess differences or similarities in the distribution of the variable among categories."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variability in Car Prices: The spread of data points along the y-axis for each car name indicates the variability in car prices within each category. Widely spread out points suggest a larger range of prices, while closely clustered points indicate a narrower price range.\n",
        "\n",
        "Central Tendency: The central tendency of the data points for each car name provides insight into the typical or median car price within that category. Comparing the central tendencies across different car names can reveal which models tend to be priced higher or lower on average.\n",
        "\n",
        "Outlier Detection: Any data points that significantly deviate from the main cluster may represent outliers. These outliers could indicate unique or premium models with exceptionally high prices or other factors affecting pricing."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Informed Pricing Strategies: Understanding the variability in car prices and identifying popular price segments can help businesses develop more informed pricing strategies. By aligning pricing with customer preferences and market demand, businesses can attract more customers and increase sales, leading to positive growth.\n",
        "\n",
        "Market Segmentation Opportunities: Insights into the distribution of car prices across different car names can help identify opportunities for market segmentation. Businesses can tailor their marketing and product offerings to target specific customer segments based on their preferences for price ranges and car models, leading to increased customer satisfaction and loyalty.\n",
        "\n",
        "Negative Business Impact:\n",
        "\n",
        "Lost Sales Opportunities: Misinterpreting pricing insights or failing to adjust pricing strategies in response to market dynamics can lead to lost sales opportunities. For example, pricing cars above the preferred price segments of target customers may result in decreased demand and negative growth.\n",
        "\n",
        "Brand Perception Damage: Inconsistent pricing or pricing outliers compared to competitors within the same car segment can damage brand perception and erode customer trust. Customers may perceive such pricing strategies as unfair or unjustified, leading to negative word-of-mouth and reputational damage"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "\n",
        "# Select the first 40 rows of data\n",
        "df_subset = df.head(40)\n",
        "\n",
        "# Create a catplot\n",
        "sns.catplot(data=df_subset, x='wheelbase', y='enginesize', kind='bar', height=6, aspect=2)\n",
        "plt.title('Wheel base V/S engine size')\n",
        "plt.xlabel('wheel base')\n",
        "plt.ylabel('engine size')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison of Distributions: Catplots provide an effective way to compare the distribution of a continuous variable across multiple categories. In this case, we can visualize how the engine size varies across different categories of wheelbase length.\n",
        "Categorical Representation: By binning the continuous variable 'wheelbase' into categories, we can transform it into a categorical variable, enabling us to explore how the relationship between wheelbase and engine size differs across distinct groups.\n",
        "Box Plot Representation: The box plot within the catplot is suitable for visualizing the distribution of a continuous variable within each category. It displays summary statistics such as median, quartiles, and outliers, providing insights into the variability and central tendency of engine sizes within each wheelbase category.\n",
        "Space Efficiency: Catplots can efficiently represent multiple distributions simultaneously, making them suitable for comparing the relationship between two variables across multiple categories."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variation in Engine Size: The box plot displays the distribution of engine sizes for different values of wheelbase. It shows how engine sizes vary across different wheelbase lengths.\n",
        "Central Tendency: The median line within each box represents the central tendency of engine sizes for a particular wheelbase length. By comparing the positions of the medians across different wheelbase lengths, we can observe any trends or differences in the central tendency of engine sizes.\n",
        "Variability: The length of the box and the whiskers indicate the variability of engine sizes within each wheelbase length category. A longer box and wider whiskers suggest greater variability, while a shorter box and narrower whiskers indicate less variability.\n",
        "Outliers: Outliers, if present, are visually identifiable as individual data points beyond the whiskers of the box plot. These outliers represent extreme values of engine size for specific wheelbase lengths.\n",
        "Relationship Between Wheelbase and Engine Size: By examining the box plot, we can assess the relationship between wheelbase and engine size. If there is a clear pattern or trend in the distribution of engine sizes across different wheelbase lengths, it suggests a potential relationship between these variables."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Product Development: Understanding the relationship between wheelbase and engine size can guide product development efforts. For example, if there's a trend of larger engine sizes for longer wheelbases, this insight can inform the development of larger and more powerful vehicles tailored to customer preferences.\n",
        "Market Segmentation: Identifying clusters of customers based on preferences for certain combinations of wheelbase and engine size can enable targeted marketing and product offerings. For instance, if there's a segment of customers who prefer compact cars with smaller engine sizes, the company can tailor marketing campaigns and product features to appeal to this segment.\n",
        "Competitive Advantage: Leveraging insights into customer preferences for specific combinations of vehicle attributes can give the company a competitive advantage. By aligning product offerings with customer preferences, the company can differentiate itself from competitors and attract more customers.\n",
        "Negative Growth:\n",
        "\n",
        "Production Costs: If there's a mismatch between customer preferences and the company's existing product lineup, it could lead to increased production costs and inefficiencies. For example, if the company continues to produce vehicles with larger engine sizes for shorter wheelbases despite a declining demand for such configurations, it may result in excess inventory and higher production costs.\n",
        "Market Saturation: If the company fails to adapt its product offerings based on changing customer preferences revealed by insights from the data, it may face challenges related to market saturation. For instance, if competitors are quick to respond to emerging trends in vehicle attributes while the company lags behind, it may lose market share and experience negative growth.\n",
        "Brand Perception: Ignoring insights into customer preferences and failing to innovate in line with market trends can negatively impact brand perception. Customers may perceive the company as outdated or out of touch with their needs, leading to decreased brand loyalty and negative growth in sales."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "\n",
        "\n",
        "# Extracting the first 40 data points\n",
        "data_subset = df.head(40)\n",
        "\n",
        "# Creating the box plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='carbody', y='carlength', data=data_subset)\n",
        "plt.xlabel('Car Body')\n",
        "plt.ylabel('Car Length')\n",
        "plt.title('Box Plot between Car Body and Car Length (First 40 Data Points)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I selected a box plot because it's a suitable choice for visualizing the distribution of a continuous variable ('carlength') across different categories or levels of a categorical variable ('carbody'). Here's why I chose this specific chart:\n",
        "\n",
        "Comparison of Distributions: Box plots provide a clear visual representation of the distribution of a continuous variable across different categories or levels of a categorical variable. In this scenario, we can compare the distribution of car lengths for various car body types.\n",
        "Identification of Outliers: Box plots display outliers as individual data points beyond the whiskers, making it easy to identify any extreme values or anomalies in the data.\n",
        "Summary Statistics: Box plots show key summary statistics such as the median, quartiles, and range of the data, providing insights into the central tendency and variability of the distribution.\n",
        "Space Efficiency: Box plots are space-efficient, making them suitable for visualizing multiple distributions simultaneously, especially when dealing with large datasets or many categories."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the box plot between 'carbody' and 'carlength', we can derive several insights:\n",
        "\n",
        "Variation in Car Length: The box plot displays the distribution of car lengths for different car body types. It shows how car lengths vary across different categories of car bodies.\n",
        "Central Tendency: The median line within each box represents the central tendency of car lengths for a particular car body type. By comparing the positions of the medians across different car body types, we can observe any trends or differences in the central tendency of car lengths.\n",
        "Variability: The length of the box and the whiskers indicate the variability of car lengths within each car body type category. A longer box and wider whiskers suggest greater variability, while a shorter box and narrower whiskers indicate less variability.\n",
        "Outliers: Outliers, if present, are visually identifiable as individual data points beyond the whiskers of the box plot. These outliers represent extreme values of car length for specific car body types.\n",
        "Relationship Between Car Body and Length: By examining the box plot, we can assess the relationship between car body type and car length. If there is a clear pattern or trend in the distribution of car lengths across different car body types, it suggests a potential relationship between these variables."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "# Extracting the first 20 data points\n",
        "data_subset = df.head(20)\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "numeric_data_subset = data_subset.select_dtypes(include=[np.number])\n",
        "correlation_matrix = numeric_data_subset.corr()\n",
        "\n",
        "# Create the correlation heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap of First 20 Data Points')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comprehensive Visualization: A correlation heatmap allows us to examine the correlation between all pairs of variables in the dataset simultaneously. This comprehensive view helps in identifying patterns and relationships that may not be immediately apparent when examining individual correlations.\n",
        "\n",
        "Color-Coding for Interpretation: The heatmap uses a color scale to represent the strength and direction of correlations, making it easy to interpret the relationships between variables. Warm colors (e.g., red) indicate positive correlations, while cool colors (e.g., blue) indicate negative correlations.\n",
        "\n",
        "Annotated Values: The heatmap can be annotated with correlation coefficients, providing precise numerical information about the strength of the relationships between variables. This makes it easy to identify strong or weak correlations and prioritize further analysis accordingly."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Correlations: Positive correlations are indicated by warmer colors (e.g., shades of red) in the heatmap. For example, we might observe strong positive correlations between certain pairs of variables such as 'carlength' and 'curbweight', or 'enginesize' and 'horsepower'. These correlations suggest that as one variable increases, the other tends to increase as well.\n",
        "\n",
        "Negative Correlations: Negative correlations are indicated by cooler colors (e.g., shades of blue) in the heatmap. We might observe negative correlations between variables such as 'citympg' and 'carprice', or 'highwaympg' and 'carprice'. These correlations suggest that as one variable increases, the other tends to decrease.\n",
        "\n",
        "Strong Correlations: Cells in the heatmap with darker shades (either dark red or dark blue) indicate stronger correlations between variables. Strong positive correlations suggest a strong linear relationship between variables, while strong negative correlations suggest an inverse relationship.\n",
        "\n",
        "Weak Correlations: Lighter shades in the heatmap (e.g., pale red or pale blue) indicate weaker correlations between variables. Weak correlations suggest a weaker linear relationship between variables, which may still be meaningful but less pronounced."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "\n",
        "# Extracting the first 10 data points\n",
        "data_subset = df.head(10)\n",
        "\n",
        "# Create the pair plot\n",
        "sns.pairplot(data_subset)\n",
        "plt.suptitle('Pair Plot of First 40 Data Points')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploratory Data Analysis: Pair plots allow for quick and easy exploration of relationships between pairs of variables. By plotting every variable against every other variable, it's possible to identify potential patterns, trends, and correlations in the data.\n",
        "\n",
        "Identifying Correlations: Pair plots are particularly useful for identifying correlations between numerical variables. By examining the scatterplots, you can visually assess the direction and strength of the relationships between variables.\n",
        "\n",
        "Diagnosing Multicollinearity: Multicollinearity occurs when two or more variables are highly correlated with each other. Pair plots can help diagnose multicollinearity by highlighting pairs of variables with strong correlations, which is important for regression analysis and other predictive modeling tasks."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation Strength: By examining the scatterplots, you can assess the strength of the relationships between pairs of variables. Strong positive correlations are indicated by tightly clustered points that follow a clear linear trend, while strong negative correlations are indicated by points that form a clear downward or upward sloping pattern.\n",
        "\n",
        "Correlation Direction: The direction of the relationship between variables can be identified by observing the slope of the scatterplots. Positive correlations are characterized by an upward sloping pattern, indicating that as one variable increases, the other variable tends to increase as well. Negative correlations are characterized by a downward sloping pattern, indicating that as one variable increases, the other variable tends to decrease.\n",
        "\n",
        "Outlier Detection: Outliers, or data points that deviate significantly from the overall pattern of the scatterplot, can be identified visually. Outliers may represent unusual or anomalous observations that warrant further investigation."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. There is a significant correlation between car price and engine size.\n",
        "2. The fuel type of a car has a significant impact on its horsepower.\n",
        "3. There is a significant difference in car prices between cars with different fuel types."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant correlation between car price and engine size.\n",
        "Alternative Hypothesis (H1): There is a significant correlation between car price and engine size.\n",
        "We will use Pearson correlation coefficient to test this hypothesis. If the p-value is less than the significance level (e.g.,  = 0.05), we reject the null hypothesis and conclude that there is a significant correlation between car price and engine size. Otherwise, we fail to reject the null hypothesis.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "car_price = df['price'].head(40)\n",
        "engine_size = df['enginesize'].head(40)\n",
        "\n",
        "# Perform Pearson correlation coefficient test\n",
        "corr_coefficient, p_value = pearsonr(car_price, engine_size)\n",
        "\n",
        "# Print the p-value\n",
        "print(\"Pearson correlation coefficient:\", corr_coefficient)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I performed the Pearson correlation coefficient test."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "I chose the Pearson correlation coefficient test because it is commonly used to measure the strength and direction of the linear relationship between two continuous variables. In this case, we want to assess whether there is a significant correlation between car price and engine size, which are both continuous variables.\n",
        "\n",
        "The Pearson correlation coefficient test provides a measure of the strength of the linear relationship between the variables, ranging from -1 to 1, where:\n",
        "\n",
        "1 indicates a perfect positive linear relationship,\n",
        "-1 indicates a perfect negative linear relationship, and\n",
        "0 indicates no linear relationship.\n",
        "Additionally, the p-value associated with the Pearson correlation coefficient test allows us to determine the statistical significance of the observed correlation. If the p-value is less than a chosen significance level (e.g.,  = 0.05), we reject the null hypothesis and conclude that there is a significant correlation between the variables. Otherwise, we fail to reject the null hypothesis.\n",
        "\n",
        "Therefore, the Pearson correlation coefficient test is suitable for assessing the relationship between car price and engine size in this scenario.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): The fuel type of a car does not have a significant impact on its horsepower.\n",
        "Alternative Hypothesis (H1): The fuel type of a car has a significant impact on its horsepower."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Extract horsepower for gas and diesel cars for the first 40 data points\n",
        "horsepower_gas = df[df['fueltype'] == 'gas']['horsepower'].head(40)\n",
        "horsepower_diesel = df[df['fueltype'] == 'diesel']['horsepower'].head(40)\n",
        "\n",
        "# Perform t-test\n",
        "t_statistic, p_value = ttest_ind(horsepower_gas, horsepower_diesel, equal_var=False)\n",
        "\n",
        "# Print the p-value\n",
        "print(\"T-Statistic:\", t_statistic)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I performed an independent samples t-test."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the independent samples t-test because it is appropriate for comparing the means of two independent groups when the dependent variable (horsepower in this case) is continuous and normally distributed (or approximately normally distributed) within each group.\n",
        "\n",
        "In this scenario, we want to assess whether there is a significant difference in horsepower between gas and diesel cars, which are two independent groups. The t-test allows us to compare the means of these two groups and determine whether the observed difference in horsepower is statistically significant.\n",
        "\n",
        "Additionally, since we are comparing two groups (gas and diesel), the t-test is suitable. If we were comparing the means across more than two groups, we would use ANOVA (Analysis of Variance) instead.\n",
        "\n",
        "Therefore, the t-test is the appropriate statistical test for testing the hypothesis regarding the impact of fuel type on horsepower in this scenario.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant difference in car prices between cars with different fuel types.\n",
        "Alternative Hypothesis (H1): There is a significant difference in car prices between cars with different fuel types."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Extract car prices for gas and diesel cars for the first 40 data points\n",
        "car_prices_gas = df[df['fueltype'] == 'gas']['price'].head(40)\n",
        "car_prices_diesel = df[df['fueltype'] == 'diesel']['price'].head(40)\n",
        "\n",
        "# Perform ANOVA test\n",
        "f_statistic, p_value = f_oneway(car_prices_gas, car_prices_diesel)\n",
        "\n",
        "# Print the p-value\n",
        "print(\"F-Statistic:\", f_statistic)\n",
        "print(\"P-value:\", p_value)"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I performed an Analysis of Variance (ANOVA) test.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the Analysis of Variance (ANOVA) test because it is appropriate for comparing the means of three or more independent groups when the dependent variable (car prices in this case) is continuous.\n",
        "\n",
        "In this scenario, we want to assess whether there is a significant difference in car prices among cars with different fuel types (gas and diesel). ANOVA allows us to simultaneously compare the means of car prices across multiple groups (in this case, gas and diesel) and determine whether there is a statistically significant difference in prices between the groups.\n",
        "\n",
        "Additionally, ANOVA is preferred when comparing more than two groups because it accounts for the overall variation among the groups and provides a single p-value to assess the significance of the observed differences.\n",
        "\n",
        "Therefore, the ANOVA test is the appropriate statistical test for testing the hypothesis regarding the difference in car prices between cars with different fuel types in this scenario.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing Values:\\n\", missing_values)\n",
        "\n",
        "# Check if missing values have been handled\n",
        "missing_values_after_imputation = df.isnull().sum()\n",
        "print(\"Missing Values After Imputation:\\n\", missing_values_after_imputation)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "n the example code provided, I used a simple imputation technique of replacing missing values with the mean of the respective column. This is a commonly used technique for handling missing numerical data. Here's why I used this technique:\n",
        "\n",
        "Mean Imputation: I used mean imputation because it is a straightforward method and is often a reasonable approach when the missing values are assumed to be missing at random (MAR). Mean imputation preserves the overall distribution of the data and minimizes the impact on the mean of the variable.\n",
        "Applicability to Numerical Data: Mean imputation is applicable to numerical data types, making it suitable for handling missing values in columns containing continuous or interval data, such as 'normalizedlosses'.\n",
        "Robustness: Mean imputation is robust to outliers since it calculates the mean based on all available data points in the column. Outliers do not disproportionately influence the imputed values.\n",
        "While mean imputation is a simple and commonly used technique, it's important to note that it has limitations and assumptions. For example, it assumes that the missing values are missing completely at random (MCAR) or missing at random (MAR), and it may lead to biased estimates if the missingness mechanism is not met. Additionally, mean imputation may not be appropriate for categorical variables or when the missingness is related to the value itself (e.g., higher-income individuals are less likely to disclose their income).\n",
        "\n",
        "Other imputation techniques, such as median imputation, mode imputation, k-nearest neighbors (KNN) imputation, or predictive modeling, may be more appropriate depending on the characteristics of the data and the nature of missingness. It's important to carefully consider the assumptions and limitations of each technique and choose the most suitable approach based on the specific dataset and analytical goals."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "\n",
        "# Identify outliers using z-score\n",
        "from scipy import stats\n",
        "z_scores = np.abs(stats.zscore(df['price']))\n",
        "threshold = 3\n",
        "outliers = df[np.abs(z_scores) > threshold]\n",
        "\n",
        "print(\"Number of outliers detected using z-score method:\", len(outliers))\n",
        "\n",
        "# Removal of outliers\n",
        "df_cleaned = df[np.abs(z_scores) <= threshold]\n",
        "\n",
        "# Transformation (log transformation)\n",
        "df['log_price'] = np.log(df['price'])\n",
        "\n",
        "# Imputation (replace outliers with median)\n",
        "median_price = df_cleaned['price'].median()\n",
        "df['price_imputed'] = np.where(np.abs(z_scores) > threshold, median_price, df['price'])\n",
        "\n",
        "# Visualize the transformed and imputed data\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(df['log_price'], kde=True)\n",
        "plt.title(\"Distribution of Log Transformed Price\")\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(df['price_imputed'], kde=True)\n",
        "plt.title(\"Distribution of Imputed Price\")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Outlier treatments\n",
        "\n",
        "# Identify outliers using z-score\n",
        "z_scores = np.abs(stats.zscore(df['price']))\n",
        "threshold = 3\n",
        "outliers = df[np.abs(z_scores) > threshold]\n",
        "\n",
        "# Remove outliers\n",
        "df_cleaned = df[np.abs(z_scores) <= threshold]\n",
        "\n",
        "# Logarithmic transformation\n",
        "df['log_price'] = np.log(df['price'])\n",
        "\n",
        "# Imputation (replace outliers with median)\n",
        "median_price = df_cleaned['price'].median()\n",
        "df['price_imputed'] = np.where(np.abs(z_scores) > threshold, median_price, df['price'])\n",
        "\n",
        "# Binning\n",
        "bins = [0, 10000, 20000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['price_bin'] = pd.cut(df['price'], bins=bins, labels=labels)\n",
        "\n",
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "# Apply winsorization to limit outliers\n",
        "win_price = winsorize(df['price'], limits=[0.05, 0.05])\n",
        "df['price_winsorized'] = win_price\n",
        "\n",
        "# Clip outliers at a threshold\n",
        "threshold = 30000\n",
        "df['price_clipped'] = df['price'].clip(upper=threshold)\n"
      ],
      "metadata": {
        "id": "ZW3myqPWGjBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Z-Score Method for Outlier Detection:\n",
        "The z-score method is a commonly used statistical technique for identifying outliers in a dataset.\n",
        "It calculates the number of standard deviations a data point is away from the mean.\n",
        "Outliers are typically defined as data points that fall outside a certain threshold (e.g., 3 standard deviations from the mean).\n",
        "This method is widely used and provides a systematic way to identify potential outliers based on their deviation from the mean.\n",
        "Winsorization for Outlier Treatment:\n",
        "Winsorization is a robust method for handling outliers by replacing extreme values with less extreme values.\n",
        "It replaces outliers with the nearest non-outlier values within a specified range (e.g., the 5th and 95th percentiles).\n",
        "Winsorization retains the overall distribution of the data while mitigating the impact of extreme values.\n",
        "This technique is suitable when removing outliers entirely may lead to loss of valuable information or bias in the dataset.\n",
        "These techniques were chosen because they are effective and widely used in practice for outlier detection and treatment. Additionally, Winsorization is a conservative approach that preserves the integrity of the data while reducing the influence of extreme values, making it suitable for various types of datasets and analytical purposes."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "data_encoded = pd.get_dummies(df, columns=categorical_columns)\n",
        "\n",
        "# Alternatively, you can use label encoding for ordinal categorical variables\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# label_encoder = LabelEncoder()\n",
        "# for col in categorical_columns:\n",
        "#     data[col] = label_encoder.fit_transform(data[col])\n",
        "\n",
        "# Print the encoded dataset\n",
        "print(\"Encoded Dataset:\")\n",
        "print(data_encoded.head())"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the provided code, I used one-hot encoding as the categorical encoding technique. Here's why I chose this technique:\n",
        "\n",
        "One-Hot Encoding:\n",
        "One-hot encoding is suitable for categorical variables with no ordinal relationship among categories.\n",
        "It represents each category as a binary (0 or 1) feature, creating a new binary column for each category in the original categorical variable.\n",
        "One-hot encoding preserves the individuality of each category and does not impose any ordinal relationship among them.\n",
        "This technique is commonly used in machine learning models, especially with algorithms that require numerical inputs.\n",
        "I did not use label encoding in this example, but it's another common categorical encoding technique. Here's a brief overview:\n",
        "\n",
        "Label Encoding:\n",
        "Label encoding assigns a unique integer to each category, thereby converting categorical variables into ordinal numerical variables.\n",
        "It is suitable for categorical variables with an ordinal relationship among categories (e.g., low, medium, high).\n",
        "Label encoding may introduce an artificial ordering to categorical variables, which may not always be appropriate, especially for non-ordinal variables.\n",
        "Label encoding is typically used when there is a clear ordinal relationship among categories and when the number of categories is large, making one-hot encoding impractical."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = df.corr().abs()\n",
        "\n",
        "# Create a mask to select upper triangle of the correlation matrix\n",
        "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "\n",
        "# Select upper triangle of correlation matrix\n",
        "upper_triangle = correlation_matrix.where(mask)\n",
        "\n",
        "# Find features with correlation above a threshold\n",
        "threshold = 0.7\n",
        "highly_correlated_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
        "\n",
        "# Drop highly correlated features\n",
        "df_cleaned = df.drop(columns=highly_correlated_features)\n",
        "\n",
        "\n",
        "# Create new feature based on the interaction between two features\n",
        "df['feature_interaction'] = df['feature1'] * df['feature2']\n",
        "\n",
        "# Create new feature by combining existing features\n",
        "df['feature_combination'] = df['feature1'] + df['feature2']\n",
        "\n",
        "# Create new feature by applying mathematical transformations\n",
        "df['feature_log'] = np.log(df['feature'])\n",
        "\n",
        "# Create new feature by binning numerical feature\n",
        "bins = [0, 10000, 20000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['feature_binned'] = pd.cut(df['feature'], bins=bins, labels=labels)\n"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "\n"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "# Select numerical features for transformation\n",
        "numerical_features = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Apply logarithmic transformation to numerical features\n",
        "data_transformed = df.copy()\n",
        "data_transformed[numerical_features] = np.log1p(data_transformed[numerical_features])\n",
        "\n",
        "# Print the transformed dataset\n",
        "print(\"Transformed Dataset:\")\n",
        "print(data_transformed.head())"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "# Min-Max Scaling (Normalization)\n",
        "scaler_minmax = MinMaxScaler()\n",
        "data_normalized = df.copy()\n",
        "data_normalized[numerical_features] = scaler_minmax.fit_transform(data_normalized[numerical_features])\n",
        "\n",
        "# Standardization (Z-score Scaling)\n",
        "scaler_standard = StandardScaler()\n",
        "data_standardized = df.copy()\n",
        "data_standardized[numerical_features] = scaler_standard.fit_transform(data_standardized[numerical_features])\n",
        "\n",
        "# Print the scaled datasets\n",
        "print(\"Normalized Dataset:\")\n",
        "print(data_normalized.head())\n",
        "\n",
        "print(\"\\nStandardized Dataset:\")\n",
        "print(data_standardized.head())"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Curse of Dimensionality: As the number of features increases, the volume of the feature space grows exponentially, which can lead to sparsity and increased computational complexity. Dimensionality reduction can help mitigate the curse of dimensionality by reducing the number of features while preserving most of the important information.\n",
        "Improved Model Performance: High-dimensional data may lead to overfitting, especially when the number of features is much larger than the number of samples. Dimensionality reduction techniques can help improve the generalization performance of machine learning models by reducing overfitting.\n",
        "Visualization: It is challenging to visualize high-dimensional data. Dimensionality reduction techniques such as PCA (Principal Component Analysis) or t-SNE (t-Distributed Stochastic Neighbor Embedding) can be used to project high-dimensional data into lower-dimensional space while preserving the structure and relationships among data points, making visualization easier.\n",
        "Feature Interpretability: In some cases, having too many features can make it difficult to interpret the model. Dimensionality reduction can help simplify the model and make it more interpretable by focusing on the most important features.\n",
        "Reduced Computational Complexity: Dimensionality reduction can lead to reduced computational complexity and memory requirements, which is beneficial for training models and performing inference, especially for large-scale datasets.\n",
        "However, dimensionality reduction may not always be necessary or beneficial. It depends on the specific characteristics of the data and the modeling task. For example:\n",
        "\n",
        "If the dataset is small and the number of features is manageable, dimensionality reduction may not be needed.\n",
        "If the features are already highly informative and there is no redundancy, dimensionality reduction may not improve model performance.\n",
        "Dimensionality reduction techniques may also introduce some loss of information, so it's essential to carefully evaluate the trade-offs between dimensionality reduction and preserving important information.\n",
        "In summary, dimensionality reduction can be beneficial for addressing the curse of dimensionality, improving model performance, aiding visualization, and reducing computational complexity. However, it should be applied judiciously based on the specific requirements and characteristics of the data and the modeling task."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Select numerical features for PCA\n",
        "numerical_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Standardize the numerical features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(df[numerical_features])\n",
        "\n",
        "# Apply PCA for dimensionality reduction\n",
        "pca = PCA(n_components=0.95)  # Preserve 95% of the variance\n",
        "pca_features = pca.fit_transform(scaled_features)\n",
        "\n",
        "# Create a DataFrame for the new PCA features\n",
        "pca_df = pd.DataFrame(data=pca_features, columns=[f'PCA_{i}' for i in range(1, pca.n_components_ + 1)])\n",
        "\n",
        "# Concatenate the new PCA features with the original dataset\n",
        "data_final = pd.concat([df, pca_df], axis=1)\n",
        "\n",
        "# Print the final dataset with PCA features\n",
        "print(\"Final Dataset with PCA Features:\")\n",
        "print(data_final.head())"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA's Ability to Preserve Variance: PCA aims to find the directions (principal components) in the feature space that capture the maximum variance in the data. By retaining the principal components that explain most of the variance, PCA effectively reduces the dimensionality of the dataset while preserving as much information as possible.\n",
        "Efficiency and Effectiveness: PCA is computationally efficient and widely used for dimensionality reduction tasks. It is particularly effective when the data exhibits linear correlations between features and when the variance is an essential criterion for capturing the underlying structure of the data.\n",
        "Interpretability: PCA produces orthogonal components, making them interpretable and facilitating the understanding of the underlying structure of the data. Each principal component represents a combination of the original features, allowing for insights into the most significant patterns in the data.\n",
        "Versatility: PCA is a versatile technique that can be applied to various types of data, including numerical data, image data, and high-dimensional datasets. It can be used for exploratory data analysis, feature extraction, and visualization tasks.\n",
        "Overall, PCA was chosen as the dimensionality reduction technique because of its ability to preserve variance, efficiency, interpretability, and versatility. It is a widely used and effective method for reducing the dimensionality of datasets while retaining most of the essential information."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In the provided code example, I used a data splitting ratio of 80% training data and 20% testing data. Here's why this ratio was chosen:\n",
        "\n",
        "Balance Between Training and Testing Data: The 80-20 split strikes a balance between having enough data for model training and having enough data for model evaluation. By allocating 80% of the data for training, we ensure that the model has sufficient samples to learn the underlying patterns in the data. At the same time, reserving 20% of the data for testing allows us to evaluate the model's performance on unseen data.\n",
        "Commonly Used Splitting Ratio: The 80-20 split is a commonly used splitting ratio in machine learning. It has been empirically found to work well across a wide range of datasets and modeling tasks. Using a well-established splitting ratio can help ensure consistency and comparability with other studies and experiments.\n",
        "Reduced Risk of Overfitting: With a larger proportion of the data allocated to training, the model has more samples to learn from, which can help reduce the risk of overfitting. Overfitting occurs when the model learns to memorize the training data rather than generalize to unseen data. By having a substantial amount of testing data, we can assess the model's ability to generalize beyond the training set.\n",
        "Adequate Evaluation: Reserving 20% of the data for testing provides an adequate amount of data for evaluating the model's performance. This allows for more reliable estimates of the model's accuracy, precision, recall, and other performance metrics.\n",
        "Overall, the 80-20 data splitting ratio strikes a balance between training and testing data, reduces the risk of overfitting, and provides adequate data for model evaluation, making it a suitable choice for many machine learning tasks."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Determining whether a dataset is imbalanced involves analyzing the distribution of the target variable (or outcome of interest) in the dataset. In the case of classification tasks, imbalance refers to a significant disparity in the distribution of classes. Here's how we can assess whether the dataset is imbalanced:\n",
        "\n",
        "Check Class Distribution: Look at the distribution of the target variable. If there is a considerable difference in the frequencies of different classes, the dataset may be imbalanced. For example, if one class dominates the dataset while others are underrepresented, it indicates an imbalance.\n",
        "Visualize Class Distribution: Plotting a histogram or bar chart of the target variable can provide a visual representation of class frequencies. If there is a noticeable skewness in the distribution, it suggests an imbalance.\n",
        "Calculate Class Ratios: Calculate the ratio of samples in each class. If the ratio between the majority class and the minority class is significantly high, it indicates class imbalance.\n",
        "Evaluate Performance Metrics: In classification tasks, evaluate performance metrics such as accuracy, precision, recall, and F1-score on both classes. If there is a notable difference in performance between classes, it may be due to class imbalance."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 linear regression\n"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "# Predict on the model\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Min-max scling\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import statsmodels.api as sm\n",
        "# VIF\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "#R-squared\n",
        "from sklearn.metrics import r2_score\n",
        "# Label encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Importing RFE\n",
        "from sklearn.feature_selection import RFE\n",
        "# Importing LinearRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# Supress warning\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Libraries for cross validation\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fueltype\n",
        "# Convert \"gas\" to 1 and \"diesel\" to 0\n",
        "df['fueltype'] = df['fueltype'].map({'gas': 1, 'diesel': 0})\n",
        "df.head()"
      ],
      "metadata": {
        "id": "sR0BMlKkKZFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aspiration\n",
        "# Convert \"std\" to 1 and \"turbo\" to 0\n",
        "df['aspiration'] = df['aspiration'].map({'std':1, 'turbo':0})\n",
        "df.head()"
      ],
      "metadata": {
        "id": "6wVTRu7rKobR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conerting doornumber, drivewheel and enginelocation 1 & 0\n",
        "\n",
        "df['doornumber'] = df['doornumber'].map({'four':1, 'two':0})\n",
        "df['drivewheel'] = df['drivewheel'].map({'fwd':1, 'rwd':0})\n",
        "df['enginelocation'] = df['enginelocation'].map({'front':1, 'rear':0})\n",
        "df.head()"
      ],
      "metadata": {
        "id": "axlEAclRK9kX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "symboling_status = pd.get_dummies(df['symboling'],drop_first=True)\n",
        "symboling_status.head()"
      ],
      "metadata": {
        "id": "4crvLvZYLjmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "symboling_status = symboling_status.rename(columns={-1:'symboling(-1)', 0:'symboling(0)', 1:'symboling(1)',2:'symboling(2)', 3:'symboling(3)'})\n",
        "df = pd.concat([df,symboling_status], axis=1)\n",
        "df = df.drop('symboling',axis=1)\n",
        "carbody_status = pd.get_dummies(df['carbody'],drop_first=True)\n",
        "carbody_status = carbody_status.rename(columns={'hardtop':'carbody(hardtop)', 'hatchback':'carbody(hatchback)', 'sedan':'carbody(sedan)','wagon':'carbody(wagon)'})\n",
        "df = pd.concat([df,carbody_status], axis=1)\n",
        "df = df.drop('carbody',axis=1)\n",
        "enginetype_status = pd.get_dummies(df['enginetype'], drop_first=True)\n",
        "enginetype_status = enginetype_status.rename(columns={'dohcv':'enginetype(dohcv)', 'l':'enginetype(l)', 'ohc':'enginetype(ohc)',\n",
        "                                                      'ohcf':'enginetype(ohcf)','ohcv':'enginetype(ohcv)' ,'rotor':'enginetype(rotor)'})\n",
        "df = pd.concat([df,enginetype_status], axis=1)\n",
        "cylindernumber_status = pd.get_dummies(df['cylindernumber'], drop_first=True)\n",
        "cylindernumber_status = cylindernumber_status.rename(columns={'five':'cylindernumber(five)', 'four':'cylindernumber(four)', 'six':'cylindernumber(six)',\n",
        "                                                      'three':'cylindernumber(three)','twelve':'cylindernumber(twelve)' ,'two':'cylindernumber(two)'})\n",
        "df = pd.concat([df,cylindernumber_status], axis=1)\n",
        "df = df.drop('cylindernumber',axis=1)\n",
        "fuelsystem_status = pd.get_dummies(df['fuelsystem'], drop_first=True)\n",
        "fuelsystem_status = fuelsystem_status.rename(columns={'2bbl':'fuelsystem(2bbl)', '4bbl':'fuelsystem(4bbl)', 'idi':'fuelsystem(idi)',\n",
        "                                                      'mfi':'fuelsystem(mfi)','mpfi':'fuelsystem(mpfi)' ,'spdi':'fuelsystem(spdi)',\n",
        "                                                             'spfi':'fuelsystem(spfi)'})\n",
        "df = pd.concat([df,fuelsystem_status], axis=1)\n",
        "df = df.drop('fuelsystem',axis=1)\n",
        "CarName_status = pd.get_dummies(df['CarName'], drop_first=True)\n",
        "CarName_status = CarName_status.rename(columns={'audi':'CarCompany(audi)', 'bmw':'CarCompany(bmw)', 'buick':'CarCompany(buick)',\n",
        "                                                      'chevrolet':'CarCompany(chevrolet)','dodge':'CarCompany(dodge)' ,'honda':'CarCompany(honda)',\n",
        "                                                      'isuzu':'CarCompany(isuzu)','jaguar':'CarCompany(jaguar)','mazda':'CarCompany(mazda)',\n",
        "                                                      'mercury':'CarCompany(mercury)','mitsubishi':'CarCompany(mitsubishi)','nissan':'CarCompany(nissan)',\n",
        "                                                      'peugeot':'CarCompany(peugeot)','plymouth':'CarCompany(plymouth)','porsche':'CarCompany(porsche)',\n",
        "                                                      'renault':'CarCompany(renault)','saab':'CarCompany(saab)','subaru':'CarCompany(subaru)',\n",
        "                                                      'toyota':'CarCompany(toyota)','volkswagen':'CarCompany(volkswagen)','volvo':'CarCompany(volvo)'})\n",
        "\n",
        "df = pd.concat([df,CarName_status], axis=1)\n",
        "df = df.drop('CarName',axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "5O4VI-6WMCB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "M0VF_DB2RADN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = train_test_split(df, train_size=0.7, random_state=100)\n",
        "print(df_train.shape)\n",
        "print(df_test.shape)"
      ],
      "metadata": {
        "id": "yyzi1gAORH_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of numeric variables. We don't need categorical variables because they are already scalled in 0 and 1.\n",
        "num_vars = ['wheelbase','carlength','carwidth','carheight','curbweight','enginesize','boreratio','stroke',\n",
        "            'compressionratio','horsepower','peakrpm','citympg','highwaympg','price']\n",
        "\n",
        "# Instantiate an object\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Fit the data in the object\n",
        "df_train[num_vars] = scaler.fit_transform(df_train[num_vars])\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "myRUElpMRPYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.describe()"
      ],
      "metadata": {
        "id": "xHC84SfXRXbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Popping out the 'price' column for y_train\n",
        "y_train = df_train.pop('price')\n",
        "# Creating X_train\n",
        "X_train = df_train"
      ],
      "metadata": {
        "id": "pvhihNMFRb4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "metadata": {
        "id": "9Ymc6Ia-RjSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "id": "-SRLBr2wRn5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm = LinearRegression()\n",
        "lm.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "zkjYPCM_Rrro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}